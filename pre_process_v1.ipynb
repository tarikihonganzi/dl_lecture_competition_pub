{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "from statistics import mode\n",
    "import json \n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_adv(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 数詞を数字に変換\n",
    "    num_word_to_digit = {\n",
    "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
    "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
    "        'ten': '10', \n",
    "    }\n",
    "    for word, digit in num_word_to_digit.items():\n",
    "        text = text.replace(word, digit)\n",
    "\n",
    "    # 小数点のピリオドを削除\n",
    "    text = re.sub(r'(?<!\\d)\\.(?!\\d)', '', text)\n",
    "\n",
    "    # 冠詞の削除\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', '', text)\n",
    "\n",
    "    # 短縮形のカンマの追加\n",
    "    contractions = {\n",
    "        \"dont\": \"don't\", \"isnt\": \"isn't\", \"arent\": \"aren't\", \"wont\": \"won't\",\n",
    "        \"cant\": \"can't\", \"wouldnt\": \"wouldn't\", \"couldnt\": \"couldn't\", \"whats\": \"what's\",\n",
    "        \"thats\": \"that's\", \"whos\": \"who's\", \"wheres\": \"where's\", \"whens\": \"when's\",\n",
    "        \"please\":\"\", \"could you\": \"can you\", \"could i\": \"can i\", \"could we\": \"can we\",\n",
    "    }\n",
    "\n",
    "    contractions_2 = {\n",
    "        \"theatre\" : \"theater\", \"colour\" : \"color\", \"centre\" : \"center\", \"favourite\" : \"favorite\",\n",
    "        \"travelling\" : \"traveling\", \"counselling\" : \"counseling\", \"metre\" : \"meter\",\n",
    "        \"cancelled\" : \"canceled\", \"labour\" : \"labor\", \"organisation\" : \"organization\",\n",
    "        \"calibre\" : \"caliber\", \"cheque\" : \"check\", \"manoeuvre\" : \"maneuver\",\n",
    "        \"neighbour\" : \"neighbor\", \"grey\" : \"gray\", \"dialogue\" : \"dialog\",\n",
    "    }\n",
    "\n",
    "    # contractions_3 = {\n",
    "    #     \"what is\": \"what's\", \"who is\": \"who's\", \"where is\": \"where's\", \"when is\": \"when's\",\n",
    "    #     \"how is\": \"how's\", \"it is\": \"it's\", \"he is\": \"he's\", \"she is\": \"she's\",\n",
    "    #     \"that is\": \"that's\", \"there is\": \"there's\", \"here is\": \"here's\",\n",
    "    #     \"i am\": \"i'm\", \"you are\": \"you're\", \"we are\": \"we're\", \"they are\": \"they're\",\n",
    "    #     \"i have\": \"i've\", \"you have\": \"you've\", \"we have\": \"we've\", \"they have\": \"they've\",\n",
    "    #     \"i will\": \"i'll\", \"you will\": \"you'll\",\n",
    "    # }\n",
    "    contractions_3 = {\n",
    "        \"what's\" : \"what is\", \"who's\" : \"who is\", \"where's\" : \"where is\", \"when's\" : \"when is\",\n",
    "        \"how's\" : \"how is\", \"it's\" : \"it is\", \"he's\" : \"he is\", \"she's\" : \"she is\",\n",
    "        \"that's\" : \"that is\", \"there's\" : \"there is\", \"here's\" : \"here is\",\n",
    "        \"i'm\" : \"i am\", \"you're\" : \"you are\", \"we're\" : \"we are\", \"they're\" : \"they are\",\n",
    "        \"i've\" : \"i have\", \"you've\" : \"you have\", \"we've\" : \"we have\", \"they've\" : \"they have\",\n",
    "        \"i'll\" : \"i will\", \"you'll\" : \"you will\",\n",
    "    }\n",
    " \n",
    "    for contraction, correct in contractions.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "    for contraction, correct in contractions_2.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "    for contraction, correct in contractions_3.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "\n",
    "    # 句読点をスペースに変換\n",
    "    text = re.sub(r\"[^\\w\\s':]\", ' ', text)\n",
    "\n",
    "    # 句読点をスペースに変換\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "\n",
    "    # 連続するスペースを1つに変換\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_adv(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 数詞を数字に変換\n",
    "    num_word_to_digit = {\n",
    "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
    "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
    "        'ten': '10', \n",
    "    }\n",
    "    for word, digit in num_word_to_digit.items():\n",
    "        text = text.replace(word, digit)\n",
    "\n",
    "    # 小数点のピリオドを削除\n",
    "    text = re.sub(r'(?<!\\d)\\.(?!\\d)', '', text)\n",
    "\n",
    "    # 冠詞の削除\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', '', text)\n",
    "\n",
    "    # 短縮形のカンマの追加\n",
    "    contractions = {\n",
    "        \"dont\": \"don't\", \"isnt\": \"isn't\", \"arent\": \"aren't\", \"wont\": \"won't\",\n",
    "        \"cant\": \"can't\", \"wouldnt\": \"wouldn't\", \"couldnt\": \"couldn't\", \"whats\": \"what's\",\n",
    "        \"thats\": \"that's\", \"whos\": \"who's\", \"wheres\": \"where's\", \"whens\": \"when's\",\n",
    "        \"please\":\"\", \"could you\": \"can you\", \"could i\": \"can i\", \"could we\": \"can we\",\n",
    "    }\n",
    "\n",
    "    contractions_2 = {\n",
    "        \"theatre\" : \"theater\", \"colour\" : \"color\", \"centre\" : \"center\", \"favourite\" : \"favorite\",\n",
    "        \"travelling\" : \"traveling\", \"counselling\" : \"counseling\", \"metre\" : \"meter\",\n",
    "        \"cancelled\" : \"canceled\", \"labour\" : \"labor\", \"organisation\" : \"organization\",\n",
    "        \"calibre\" : \"caliber\", \"cheque\" : \"check\", \"manoeuvre\" : \"maneuver\",\n",
    "        \"neighbour\" : \"neighbor\", \"grey\" : \"gray\", \"dialogue\" : \"dialog\",\n",
    "    }\n",
    "\n",
    "    # contractions_3 = {\n",
    "    #     \"what is\": \"what's\", \"who is\": \"who's\", \"where is\": \"where's\", \"when is\": \"when's\",\n",
    "    #     \"how is\": \"how's\", \"it is\": \"it's\", \"he is\": \"he's\", \"she is\": \"she's\",\n",
    "    #     \"that is\": \"that's\", \"there is\": \"there's\", \"here is\": \"here's\",\n",
    "    #     \"i am\": \"i'm\", \"you are\": \"you're\", \"we are\": \"we're\", \"they are\": \"they're\",\n",
    "    #     \"i have\": \"i've\", \"you have\": \"you've\", \"we have\": \"we've\", \"they have\": \"they've\",\n",
    "    #     \"i will\": \"i'll\", \"you will\": \"you'll\",\n",
    "    # }\n",
    "    contractions_3 = {\n",
    "        \"what's\" : \"what is\", \"who's\" : \"who is\", \"where's\" : \"where is\", \"when's\" : \"when is\",\n",
    "        \"how's\" : \"how is\", \"it's\" : \"it is\", \"he's\" : \"he is\", \"she's\" : \"she is\",\n",
    "        \"that's\" : \"that is\", \"there's\" : \"there is\", \"here's\" : \"here is\",\n",
    "        \"i'm\" : \"i am\", \"you're\" : \"you are\", \"we're\" : \"we are\", \"they're\" : \"they are\",\n",
    "        \"i've\" : \"i have\", \"you've\" : \"you have\", \"we've\" : \"we have\", \"they've\" : \"they have\",\n",
    "        \"i'll\" : \"i will\", \"you'll\" : \"you will\",\n",
    "    }\n",
    " \n",
    "    for contraction, correct in contractions.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "    for contraction, correct in contractions_2.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "    for contraction, correct in contractions_3.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "\n",
    "    # 句読点をスペースに変換\n",
    "    text = re.sub(r\"[^\\w\\s':]\", ' ', text)\n",
    "\n",
    "    # 句読点をスペースに変換\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "\n",
    "    # 連続するスペースを1つに変換\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 数詞を数字に変換\n",
    "    num_word_to_digit = {\n",
    "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
    "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
    "        'ten': '10'\n",
    "    }\n",
    "    for word, digit in num_word_to_digit.items():\n",
    "        text = text.replace(word, digit)\n",
    "\n",
    "    # 小数点のピリオドを削除\n",
    "    text = re.sub(r'(?<!\\d)\\.(?!\\d)', '', text)\n",
    "\n",
    "    # 冠詞の削除\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', '', text)\n",
    "\n",
    "    # 短縮形のカンマの追加\n",
    "    contractions = {\n",
    "        \"dont\": \"don't\", \"isnt\": \"isn't\", \"arent\": \"aren't\", \"wont\": \"won't\",\n",
    "        \"cant\": \"can't\", \"wouldnt\": \"wouldn't\", \"couldnt\": \"couldn't\"\n",
    "    }\n",
    "    for contraction, correct in contractions.items():\n",
    "        text = text.replace(contraction, correct)\n",
    "\n",
    "    # 句読点をスペースに変換\n",
    "    text = re.sub(r\"[^\\w\\s':]\", ' ', text)\n",
    "\n",
    "    # 句読点をスペースに変換\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "\n",
    "    # 連続するスペースを1つに変換\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_data(df_path, image_dir=\"\", transform=None, answer=False):\n",
    "\n",
    "    df = pandas.read_json(df_path)\n",
    "\n",
    "    # question / answerの辞書を作成\n",
    "    question2idx = {}\n",
    "    answer2idx = {}\n",
    "    questionInitialWords = dict()\n",
    "    c1 = c2 = c3 = c4 = c5 = c6 = c7 = 0\n",
    "\n",
    "    first_three_words = []\n",
    "    first_four_words = []\n",
    "\n",
    "    # 質問文に含まれる単語を辞書に追加\n",
    "    for question in df[\"question\"]:\n",
    "        question = process_text_adv(question)\n",
    "        words = question.split(\" \")\n",
    "\n",
    "        if len(words) > 2:\n",
    "            first_three_words.append(words[0] + \" \" + words[1] + \" \" + words[2])\n",
    "            if len(words) > 3:\n",
    "                first_four_words.append(words[0] + \" \" + words[1] + \" \" + words[2] + \" \" + words[3])\n",
    "            \n",
    "        for idex, word in enumerate(words):\n",
    "            if idex == 0:\n",
    "                if word not in questionInitialWords:\n",
    "                    questionInitialWords[word] = 1\n",
    "                else:\n",
    "                    questionInitialWords[word] += 1            \n",
    "            if word not in question2idx:\n",
    "                question2idx[word] = len(question2idx)\n",
    "    idx2question = {v: k for k, v in question2idx.items()}  # 逆変換用の辞書(question)\n",
    "\n",
    "    if answer:\n",
    "        # 回答に含まれる単語を辞書に追加\n",
    "        for answers in df[\"answers\"]:\n",
    "            for answer in answers:\n",
    "                word = answer[\"answer\"]\n",
    "                word = process_text(word)\n",
    "                if word not in answer2idx:\n",
    "                    answer2idx[word] = len(answer2idx)\n",
    "        idx2answer = {v: k for k, v in answer2idx.items()}  # 逆変換用の辞書(answer)\n",
    "\n",
    "    return first_three_words, first_four_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"answers\":{\"0\":[{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"flat iron beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"flat iron beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"},{\"answer_confidence\":\"yes\",\"answer\":\"beef chuck steak\"}],\"1\":[{\"answer_confidence\":\"yes\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"yes\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"yes\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"yes\",\"answer\":\"candle\"},{\"answer_confidence\":\"no\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"maybe\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"yes\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"yes\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"no\",\"answer\":\"unanswerable\"},{\"answer_confidence\":\"yes\",\"answer\":\"unanswerable\"}],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# COCO_val2014_000000393075\n",
    "\n",
    "answer_type = dict()\n",
    "extra_answer_output = dict()\n",
    "\n",
    "print(\"test\")\n",
    "# データセットの読み込み\n",
    "with open('./extra_data/train_question.json', 'r') as f:\n",
    "    question_data = json.load(f)\n",
    "\n",
    "with open('./extra_data/train_answer.json', 'r') as f:\n",
    "    answer_data = json.load(f)\n",
    "\n",
    "extra_questions_data = question_data[\"questions\"]\n",
    "extra_answer_data = answer_data[\"annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "214354\n",
      "{'image_id': 262148, 'question': 'Where is he looking?', 'question_id': 262148000}\n",
      "{'question_type': 'none of the above', 'multiple_choice_answer': 'down', 'answers': [{'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 1}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 2}, {'answer': 'at table', 'answer_confidence': 'yes', 'answer_id': 3}, {'answer': 'skateboard', 'answer_confidence': 'yes', 'answer_id': 4}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 5}, {'answer': 'table', 'answer_confidence': 'yes', 'answer_id': 6}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 7}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 8}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 9}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 10}], 'image_id': 262148, 'answer_type': 'other', 'question_id': 262148000}\n",
      "question_counter: 21093\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "print(len(extra_questions_data))\n",
    "print(extra_questions_data[0])\n",
    "\n",
    "start_number = 19873\n",
    "\n",
    "three_words_1, four_words_1 = original_data('./data/train.json')\n",
    "three_words_2, four_words_2 = original_data('./data/valid.json')\n",
    "\n",
    "counter = counter_four = counter_only_three = 0\n",
    "\n",
    "selected_question_list = []\n",
    "\n",
    "question_map_dict = dict()\n",
    "image_dict = dict()\n",
    "question_dict = dict()\n",
    "final_dict = dict()\n",
    "\n",
    "question_counter = 0\n",
    "\n",
    "for data in extra_questions_data:\n",
    "    \n",
    "    question = data[\"question\"]\n",
    "    parsed_question = process_text_adv(question)\n",
    "\n",
    "    original_image_id = data[\"image_id\"]\n",
    "    question_id = data[\"question_id\"]\n",
    "\n",
    "    new_first_three_words = \"\"\n",
    "    new_first_four_words = \"\"\n",
    "\n",
    "    question_split = parsed_question.split(\" \")\n",
    "\n",
    "    if len(question_split) > 2:\n",
    "        new_first_three_words = question_split[0] + \" \" + question_split[1] + \" \" + question_split[2]\n",
    "    if len(question_split) > 3:\n",
    "        new_first_four_words = question_split[0] + \" \" + question_split[1] + \" \" + question_split[2] + \" \" + question_split[3]\n",
    "\n",
    "    iscontinue = True\n",
    "\n",
    "    if new_first_three_words in three_words_2:\n",
    "        counter += 1\n",
    "        if len(question_split) > 3:\n",
    "            if new_first_four_words in four_words_1:\n",
    "                counter_four += 1\n",
    "                iscontinue = False\n",
    "        else:\n",
    "            counter_only_three += 1\n",
    "            iscontinue = False\n",
    "\n",
    "\n",
    "    if new_first_three_words in three_words_1:    \n",
    "        counter += 1\n",
    "        if len(question_split) > 3:\n",
    "            if new_first_four_words in four_words_2:\n",
    "                counter_four += 1\n",
    "                iscontinue = False\n",
    "        else:\n",
    "            counter_only_three += 1\n",
    "            iscontinue = False\n",
    "    \n",
    "    if iscontinue:\n",
    "        continue\n",
    "\n",
    "    question_counter += 1\n",
    "\n",
    "    image_name = \"COCO_train2014_\" + str(original_image_id).zfill(12) + \".jpg\"\n",
    "\n",
    "    selected_question_list.append(question_id)\n",
    "    \n",
    "    question_map_dict[question_id] = start_number\n",
    "    image_dict[start_number] = image_name\n",
    "    re_question_id = start_number\n",
    "    \n",
    "    question_dict[re_question_id] = question\n",
    "\n",
    "    start_number += 1\n",
    "\n",
    "\n",
    "final_dict[\"image\"] = image_dict\n",
    "final_dict[\"question\"] = question_dict\n",
    "\n",
    "print(extra_answer_data[0])\n",
    "\n",
    "print(f\"question_counter: {question_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./extra_data/test_question.json', 'w') as f:\n",
    "#     json.dump(question_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./extra_data/test_image.json', 'w') as f:\n",
    "#     json.dump(image_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer_confidence': 'yes', 'answer': 'beige'}, {'answer_confidence': 'yes', 'answer': 'white'}, {'answer_confidence': 'no', 'answer': 'pink'}, {'answer_confidence': 'yes', 'answer': 'white'}, {'answer_confidence': 'yes', 'answer': 'white'}, {'answer_confidence': 'yes', 'answer': 'white'}, {'answer_confidence': 'yes', 'answer': 'yellow'}, {'answer_confidence': 'yes', 'answer': 'yellow'}, {'answer_confidence': 'yes', 'answer': 'beige'}, {'answer_confidence': 'maybe', 'answer': 'yellow'}]\n",
      "min_image_id: 136\n",
      "answer_counter: 21093\n"
     ]
    }
   ],
   "source": [
    "min_image_id = 999999999999999999\n",
    "\n",
    "answer_counter = 0\n",
    "\n",
    "for data in extra_answer_data:\n",
    "    question_id = data[\"question_id\"]\n",
    "\n",
    "    if question_id not in selected_question_list:\n",
    "        continue\n",
    "\n",
    "    re_question_id = question_map_dict[question_id]\n",
    "\n",
    "    image_id = data[\"image_id\"]\n",
    "    if image_id < min_image_id:\n",
    "        min_image_id = image_id\n",
    "    answer_list = data['answers']\n",
    "    replace_answer_list = []\n",
    "    for answer in answer_list:\n",
    "        answer_data = dict()\n",
    "        answer_data[\"answer_confidence\"] = answer[\"answer_confidence\"]\n",
    "        answer_data[\"answer\"] = answer[\"answer\"]\n",
    "        answer = answer_data\n",
    "        replace_answer_list.append(answer_data)\n",
    "    extra_answer_output[re_question_id] = replace_answer_list\n",
    "    answer_counter += 1\n",
    "\n",
    "final_dict[\"answers\"] = extra_answer_output\n",
    "\n",
    "print(f\"{extra_answer_output[19873]}\")\n",
    "print(f\"min_image_id: {min_image_id}\")\n",
    "print(f\"answer_counter: {answer_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./extra_data/test.json', 'w') as f:\n",
    "    json.dump(extra_answer_output, f, indent=2)\n",
    "\n",
    "with open('./extra_data/final_valie.json', 'w') as f:\n",
    "    json.dump(final_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VQADataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mVQADataset\u001b[49m(df_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/train.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VQADataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = VQADataset(df_path=\"./data/train.json\", image_dir=\"./data/train\", transform=transform_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
